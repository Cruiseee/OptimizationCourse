{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Minimization with Nonlinear Constraints: Foundations\n",
    "Direction Requirements\n",
    "Descent and Feasible Cones\n",
    "Conditions for an Optimum\n",
    "Direction Requirements\n",
    "The first step in many nonlinear optimization techniques is to start on the boundary of the feasible region – it doesn’t matter which boundary or where on the boundary you start.\n",
    "Direction Requirements: Descent\n",
    "Any vector that will decrease the objective function is said to move in a descent direction. Although the objective function isn’t shown on the graph, you will have its equation.\n",
    "To test if a vector is moving in a descent direction, \n",
    "Find the gradient of the objective function at the current point.\n",
    "Find the dot product of the gradient with the proposed vector.\n",
    "If the dot product is negative, then the vector is moving in a descent direction.\n",
    "Direction Requirements: Descent\n",
    "An example: Suppose you are trying to minimize f(x) = 10x12 – 4x1x2, starting at the point (3, 5). \n",
    "The gradient is [20x1–4x2      -4x1]. \n",
    "At (3, 5), the value of the gradient is [40  -12].\n",
    "To test the vector <2, 3>, find the dot product with the gradient: 40·2 - 12·3 is positive, so this is not a descent vector.\n",
    "The vector <-1, 5>, however, is a descent vector. Verify this using the dot product with the gradient. \n",
    "Practice Problem 1\n",
    "Given the objective function \n",
    "f(x) = 2x1 + 3x1x22\n",
    "tell if the following vectors are in a descent direction from starting point (4, -2). \n",
    "<2, 1>\t\t\t\n",
    "<2, -1>\t\t\t\n",
    "<-2, -1>\t\t\t\n",
    "<-2, 1>\t\t\t\n",
    "Direction Requirements: Feasible\n",
    "A vector that will not violate the constraints is said to move in a feasible direction. Because the constraints are graphed, you can visualize this:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "However, there is also some math involved.  \n",
    "Direction Requirements: Feasible\n",
    "To determine whether a vector lies in a feasible direction, we need to focus on the equation of the constraint on which the initial point lies, which will be in this form:\n",
    "\n",
    "\tgj(x) ≤ 0\n",
    "\n",
    "On the boundary of this constraint, gj(x) = 0. A feasible vector can not cause the value of gj to increase. gj must either decrease or remain 0.\n",
    "Direction Requirements: Feasible\n",
    "Just as the gradient of the objective function f can test a vector for decrease in f, the gradient of a constraint g can test a vector for decrease in g. \n",
    "In other words, the steps are the same:\n",
    "To test if a vector is moving in a feasible direction, \n",
    "Find the gradient of the constraint at the current point.\n",
    "Find the dot product of that gradient with the proposed vector.\n",
    "If the dot product is negative or 0, then the vector is moving in a feasible direction.\n",
    "Practice Problem 2\n",
    "Given the constraint x1 + x22 – 4 ≤ 0,\n",
    "Choose any point on the boundary of this constraint. \n",
    "Test the vectors <3, 4>, <-5, 4>, <-3, -2> and <3, -8> for feasibility.\n",
    "Choose a different point and test the same vectors.\n",
    "Practice Problem 3\n",
    "Given the objective function \n",
    "\tminimize f(x) = x1 + 3x22\n",
    "and initial point (4,) on constraint\n",
    "\tg1(x) = x12 + x22 – 24 ≤ 0\n",
    "Find which of the following vectors are in both feasible and descent directions:\n",
    "<-1, 0>\tb. <1, 0>\tc. <0, -1>\td. <0, 1>\n",
    "e.  <1, 1>\tf. <1, -1>\tg. <-1, 1>\th. <-1, -1>\n",
    "\n",
    "Descent and Feasible Cones\n",
    "Since the initial point is randomly chosen, there is a good chance that the overlap between the set of all feasible vectors (called the feasible cone) and the set of all descent vectors (called the descent cone) is large.\n",
    "\n",
    "\n",
    "\n",
    "A productive vector must fall in this overlap: it must be feasible, and it must also decrease the objective function.\n",
    "Descent and Feasible Cones\n",
    "As we approach the minimum point, however, the overlap will get smaller and smaller. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Eventually there will be no overlap at all.\n",
    "Descent and Feasible Cones\n",
    "If there is no overlap between the feasible cone and the descent cone, you have reached an optimal point. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "At this point, you can not decrease the objective function any further without violating the constraint.\n",
    "Practice Problem 4\n",
    "Suppose, at a certain point, you have a descent gradient [3, 1] and are testing a vector <v1, v2>. Write an inequality that must be satisfied for the vector to be in a descent direction.\n",
    "Suppose, at the same point, you have a constraint gradient [1, -1]. Write an inequality that must be satisfied for the vector <v1, v2> to be in a feasible direction. \n",
    "Graph both inequalities on the same axis. Do they overlap?\n",
    "\n",
    "Practice Problem 5\n",
    "Graph the overlap region for a descent gradient [3,   -1] and a constraint gradient [-2, 1].\n",
    "Graph the overlap region for a descent gradient [4, 2] and a constraint gradient [-2, -1].\n",
    "Calculate the determinants of matrices whose columns are the descent and constraint gradients you have tested so far:\n",
    ",   and \n",
    "Draw a conclusion about the relationship of the determinant and the overlap of the feasible and descent cones.\n",
    "Conditions for an Optimal Point\n",
    "Hopefully you noticed, on practice problem 5, that gradients that go in opposite directions have a matrix determinant of 0. \n",
    "\n",
    "\n",
    "\n",
    "This is related to the fact that the value of the determinant is the area of a parallelogram formed by the component vectors. \n",
    "If the vectors go in exactly the same direction, or go in opposite directions, the area of the parallelogram will be 0.\n",
    "Conditions for an Optimal Point\n",
    "So, one way to know that you have reached an optimal point is:\n",
    "The descent and gradient vector have a matrix determinant of 0 AND\n",
    "The descent and gradient vector are not going in the same direction.\n",
    "The second point can be determined simply by looking at the signs (positive or negative) of the components: same sign = same direction. Also, the dot product of the two gradients will be negative.\n",
    "Conditions for an Optimal Point\n",
    "Another possibility is that the optimal value occurs in the interior of the feasible region rather than on a boundary. \n",
    "In this case the gradient of the objective function will equal zero at that point, just as the derivative equals zero at optimal points on 1-variable functions. \n",
    "Conditions for an Optimal Point\n",
    "However, a gradient value of 0 is not enough to guarantee an optimal value: you must still check the eigenvalues of the Hessian to determine concavity. \n",
    "Practice Problem 6\n",
    "Using the objective function f(x) = x12 + x1 + 2x22 and the constraint gradient [1 + x2   x1], determine whether an optimal point has been reached at:\n",
    "a. (1, 5)\n",
    "b. (1.765564, -2)\n",
    "c. (-0.5, 0)\n",
    "d. (2.5, 1.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.5.2",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
